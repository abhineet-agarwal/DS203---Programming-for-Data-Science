{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pyspark\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the spark context\n",
    "sc = pyspark.SparkContext(appName=\"RDDFromBasics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now initialize the spark session\n",
    "ss = pyspark.sql.SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dataframe reader\n",
    "dfr = ss.read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the schema so that it can be passed to the read function\n",
    "schemaStruct = StructType()\n",
    "schemaStruct.add(\"SYMBOL\", StringType(), True)\n",
    "schemaStruct.add(\"SERIES\", StringType(), True)\n",
    "schemaStruct.add(\"OPEN\", DoubleType(), True)\n",
    "schemaStruct.add(\"HIGH\", DoubleType(), True)\n",
    "schemaStruct.add(\"LOW\", DoubleType(), True)\n",
    "schemaStruct.add(\"CLOSE\", DoubleType(), True)\n",
    "schemaStruct.add(\"LAST\", DoubleType(), True)\n",
    "schemaStruct.add(\"PREVCLOSE\", DoubleType(), True)\n",
    "schemaStruct.add(\"TOTTRDQTY\", LongType(), True)\n",
    "schemaStruct.add(\"TOTTRDVAL\", DoubleType(), True)\n",
    "schemaStruct.add(\"TIMESTAMP\", StringType(), True)\n",
    "schemaStruct.add(\"ADDNL\", StringType(), True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the csv file. But first set header to true and ask to infer schema automatically\n",
    "df = dfr.csv(\"/home/hduser/spark/nsedata.csv\", schema=schemaStruct, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the schema that has been inferred by SPARK\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out the number of lines in the file\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfGeometric = df.select(\"SYMBOL\", \"OPEN\", \"HIGH\", \"LOW\", \"CLOSE\", \"TIMESTAMP\").where(\"SYMBOL='GEOMETRIC'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfGeometric.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary view using the dataframe, and query it using sql\n",
    "df.createTempView(\"stocks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you can query the dataframe using sql\n",
    "sqlres = ss.sql(\"select * from stocks where SYMBOL == 'GEOMETRIC' limit 10\")\n",
    "print(type(sqlres))\n",
    "sqlres.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = sqlres.describe(\"OPEN\",\"HIGH\",\"LOW\",\"CLOSE\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlres.agg({\"OPEN\":\"max\"}).show()\n",
    "#print(sqlres.agg({\"OPEN\":\"max\"}).collect())\n",
    "#print(sqlres.agg({\"OPEN\":\"mean\"}).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.where(\"SYMBOL == 'GEOMETRIC' and TIMESTAMP like '%APR-2011'\").describe(\"OPEN\", \"HIGH\", \"LOW\", \"CLOSE\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.stop()\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
